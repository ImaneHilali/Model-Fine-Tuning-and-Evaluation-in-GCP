{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a27f4a-8b86-4b7e-92a1-8e8074d27a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.35.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.34.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "!pip install transformers datasets torch sentencepiece google-cloud-storage accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ab2c76-8900-42e5-bcd8-8533b1602760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# Initialize GCS client\n",
    "client = storage.Client()\n",
    "\n",
    "bucket_name = 'translation-datasets'\n",
    "train_file_path = f'gs://{bucket_name}/train.jsonl'\n",
    "validation_file_path = f'gs://{bucket_name}/validation.jsonl'\n",
    "test_file_path = f'gs://{bucket_name}/test.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50b7ba-bf28-4dcd-9555-fdad4632b453",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source_lang': 'en', 'target_lang': 'fr', 'source_text': '\"Wait: I have your name here.', 'target_text': \"—Attendez, j'ai la votre nom.\"}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load datasets from GCS bucket\n",
    "train_data = load_dataset('json', data_files={'train': train_file_path})['train']\n",
    "validation_data = load_dataset('json', data_files={'validation': validation_file_path})['validation']\n",
    "test_data = load_dataset('json', data_files={'test': test_file_path})['test']\n",
    "\n",
    "# Verify loaded data\n",
    "print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f09d5-a0a0-42e0-a7a8-4e76a1f171ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the NLLB tokenizer\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Language code mapping for NLLB\n",
    "lang_code_map = {\n",
    "    \"fr\": \"fra_Latn\",\n",
    "    \"en\": \"eng_Latn\",\n",
    "    \"es\": \"spa_Latn\",\n",
    "    \"de\": \"deu_Latn\",\n",
    "    \"it\": \"ita_Latn\",\n",
    "    \"pt\": \"por_Latn\",\n",
    "    \"zh\": \"zho_Hans\",\n",
    "    \"ja\": \"jpn_Jpan\",\n",
    "    \"ar\": \"arb_Arab\",\n",
    "    \"hi\": \"hin_Deva\",\n",
    "    \"ru\": \"rus_Cyrl\",\n",
    "    \"ko\": \"kor_Hang\",\n",
    "    \"tr\": \"tur_Latn\",\n",
    "    \"nl\": \"nld_Latn\",\n",
    "    \"sv\": \"swe_Latn\",\n",
    "    \"pl\": \"pol_Latn\",\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c4a90-fcb5-4202-a72b-26be616ab607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['source_lang', 'target_lang', 'source_text', 'target_text']\n",
      "{'source_lang': 'en', 'target_lang': 'fr', 'source_text': '\"Wait: I have your name here.', 'target_text': \"—Attendez, j'ai la votre nom.\"}\n"
     ]
    }
   ],
   "source": [
    "# Check the column names of the dataset\n",
    "print(train_data.column_names)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1575434-2e79-402d-aa85-0bf2190405ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "\n",
    "    tokenizer.src_lang = examples['source_lang'][0]\n",
    "    tokenizer.tgt_lang = examples['target_lang'][0]\n",
    "    \n",
    "    # Extract source and target sentences\n",
    "    inputs = examples['source_text']\n",
    "    targets = examples['target_text']\n",
    "    \n",
    "    # Tokenize the source and target texts with padding and truncation\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        text_target=targets,\n",
    "        max_length=128,\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf590748-21fb-486f-a4ee-f41b0e73bc00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the preprocessing to the datasets\n",
    "tokenized_train = train_data.map(preprocess_function, batched=True)\n",
    "tokenized_validation = validation_data.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_data.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0f8d4-01c3-48ff-8edf-f8ab6ef2a096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "# Define training arguments with a matching save and evaluation strategy\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./nllb-finetuned\",\n",
    "    eval_strategy=\"steps\",  # Evaluate at the end of each epoch\n",
    "    save_strategy=\"steps\",  # Save based on steps\n",
    "    save_steps=3600,  # Save a checkpoint every 3600 steps (approx 1 hour)\n",
    "    eval_steps=3600,  # Evaluate every 3600 steps (matches save_steps)\n",
    "    per_device_train_batch_size=4,  # Reduce batch size\n",
    "    per_device_eval_batch_size=4,   # Reduce evaluation batch size\n",
    "    gradient_accumulation_steps=2,  # Accumulate gradients over 2 steps to simulate batch size of 16\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,  # Enable mixed precision for faster training on supported GPUs\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True  # Ensure best model is loaded at the end\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d2ae7-704d-401f-b422-40166331859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "class UploadCheckpointToGCS(TrainerCallback):\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        # Path to the local checkpoint directory\n",
    "        checkpoint_dir = f\"{args.output_dir}/checkpoint-{state.global_step}\"\n",
    "        \n",
    "        # Upload to GCS bucket\n",
    "        bucket_name = \"translation-datasets\"\n",
    "        destination = f\"gs://{bucket_name}/nllb-finetuned/checkpoint-{state.global_step}\"\n",
    "        \n",
    "        # Run the gsutil command to upload the checkpoint to GCS\n",
    "        subprocess.run(f\"gsutil cp -r {checkpoint_dir} {destination}\", shell=True)\n",
    "        print(f\"Uploaded checkpoint {state.global_step} to {destination}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db924113-e699-45f5-a9f0-73103d9fb138",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, AutoModelForSeq2SeqLM, EarlyStoppingCallback, DataCollatorWithPadding\n",
    "\n",
    "# Define the data collator to handle padding dynamically\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "\n",
    "# Load the NLLB model\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Define the trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_validation,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2), UploadCheckpointToGCS()]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c154cb1-b6ba-4112-8ec1-c80d8158c173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6576' max='168660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6576/168660 5:03:30 < 124:43:02, 0.36 it/s, Epoch 0.39/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.463200</td>\n",
       "      <td>0.442232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/optimizer.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/trainer_state.json [Content-Type=application/json]...\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/config.json [Content-Type=application/json]...\n",
      "/ [4 files][  6.9 GiB/  6.9 GiB]   99.6 MiB/s                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/scheduler.pt [Content-Type=application/vnd.snesdev-page-table]...\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/rng_state.pth [Content-Type=application/octet-stream]...\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/sentencepiece.bpe.model [Content-Type=application/octet-stream]...\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/generation_config.json [Content-Type=application/json]...\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./nllb-finetuned/checkpoint-3600/training_args.bin [Content-Type=application/octet-stream]...\n",
      "| [12 files][  6.9 GiB/  6.9 GiB]   60.7 MiB/s                                  \n",
      "Operation completed over 12 objects/6.9 GiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded checkpoint 3600 to gs://vosyncore-translation-datasets/nllb-finetuned/checkpoint-3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08729377-b2ef-4ce5-a8d1-f8cbd5a7c232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload to GCS\n",
    "!gsutil cp -r ./nllb-finetuned gs://{bucket_name}/nllb-finetuned\n",
    "\n",
    "# push to Hugging Face Hub\n",
    "#model.push_to_hub(\"my-finetuned-nllb-model\")\n",
    "#tokenizer.push_to_hub(\"my-finetuned-nllb-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7095a67-f97b-4c3e-878d-b3f381b82452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4217' max='4217' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4217/4217 31:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.062021255493164, 'eval_runtime': 1882.0286, 'eval_samples_per_second': 17.923, 'eval_steps_per_second': 2.241}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "eval_results = trainer.evaluate(eval_dataset=tokenized_test)\n",
    "\n",
    "print(eval_results)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
